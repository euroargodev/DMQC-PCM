{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import pandas as pd\n",
    "\n",
    "import pyxpcm\n",
    "from pyxpcm.models import pcm\n",
    "\n",
    "import Plotter\n",
    "from Plotter import Plotter\n",
    "\n",
    "from BIC_calculation import *\n",
    "\n",
    "from classif_functions import *\n",
    " \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __User inputs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = '/home1/homedir5/perso/agarciaj/EARISE/DMQC-PCM/OWC-pcm/matlabow/ow_config.txt'\n",
    "\n",
    "with open(config_filename) as f:\n",
    "    file_content = '[configuration]\\n' + f.read()\n",
    "\n",
    "config_parser = configparser.RawConfigParser(comment_prefixes='%')\n",
    "config_parser.read_string(file_content)\n",
    "config = config_parser['configuration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in config_parser['configuration']:  \n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['config_wmo_boxes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference data selection and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth for interpolation\n",
    "max_depth = 1000\n",
    "# chose season ('DJF', 'MAM', 'JJA', 'SON' or 'all') for training dataset\n",
    "season = ['all']\n",
    "# paths\n",
    "WMOboxes_latlon='WMO_boxes_latlon.txt'\n",
    "#wmo_boxes= config['config_directory'] + config['config_wmo_boxes']\n",
    "wmo_boxes='wmo_boxes_argo.mat'\n",
    "#ref_path = '/home1/homedir5/perso/agarciaj/EARISE/OW/matlabow/data/climatology/'\n",
    "ref_path = config['historical_directory']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Float you want to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agulhas current\n",
    "float_mat_path = config['float_source_directory'] + '/test3/3901915.mat'\n",
    "float_WMO = 3901915\n",
    "# southern ocean\n",
    "#float_mat_path = config['float_source_directory'] + '/test2/3901928.mat'\n",
    "#float_WMO = 3901928\n",
    "# north atlantic \n",
    "#float_mat_path = '/home1/homedir5/perso/agarciaj/EARISE/DMQC-PCM/OWC-pcm/matlabow/data/float_source/test1/4900136.mat'\n",
    "#float_WMO = 4900136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load argo reference database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load argo reference database__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = get_refdata(float_mat_path = float_mat_path, \n",
    "                 WMOboxes_latlon = WMOboxes_latlon, \n",
    "                 wmo_boxes = wmo_boxes, \n",
    "                 ref_path = ref_path,\n",
    "                 config = config,\n",
    "                 map_pv_use = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 4), dpi=120, facecolor='w', edgecolor='k')\n",
    "sc = ax.pcolor(np.tile(np.arange(len(ds['n_profiles'])), (len(ds['n_pres']),1)), ds['pres'], ds['temp'], cmap='viridis')\n",
    "ax.invert_yaxis()\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label('Temperature (Â°C)', fontsize=10)\n",
    "ax.tick_params(axis=\"x\", labelsize=8)\n",
    "ax.tick_params(axis=\"y\", labelsize=8)\n",
    "ax.set_ylabel('Presure (dbar)', fontsize=10);\n",
    "ax.set_xlabel('n_profiles', fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Interpolate to standard levels__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_lev = np.arange(0,max_depth)\n",
    "ds = interpolate_standard_levels(ds, std_lev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some format\n",
    "#pres should be negative for the PCM\n",
    "ds['PRES_INTERPOLATED'] = -np.abs(ds['PRES_INTERPOLATED'].values)\n",
    "#axis attributtes for plotter class\n",
    "ds.PRES_INTERPOLATED.attrs['axis'] = 'Z'\n",
    "ds.lat.attrs['axis'] = 'Y'\n",
    "ds.long.attrs['axis'] = 'X'\n",
    "ds.dates.attrs['axis'] = 'T'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['temp'].plot(x='n_profiles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial distribution of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj=ccrs.PlateCarree()\n",
    "subplot_kw = {'projection': proj}\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(\n",
    "            12, 12), dpi=120, facecolor='w', edgecolor='k', subplot_kw=subplot_kw)\n",
    "\n",
    "p1 = ax.scatter(ds['long'], ds['lat'], s=3, transform=proj, label='Argo reference data')\n",
    "\n",
    "land_feature = cfeature.NaturalEarthFeature(\n",
    "            category='physical', name='land', scale='50m', facecolor=[0.9375, 0.9375, 0.859375])\n",
    "ax.add_feature(land_feature, edgecolor='black')\n",
    "\n",
    "defaults = {'linewidth': .5, 'color': 'gray', 'alpha': 0.5, 'linestyle': '--'}\n",
    "gl = ax.gridlines(crs=ax.projection,draw_labels=True, **defaults)\n",
    "gl.xlocator = mticker.FixedLocator(np.arange(-180, 180+1, 4))\n",
    "gl.ylocator = mticker.FixedLocator(np.arange(-90, 90+1, 4))\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'fontsize': 5}\n",
    "gl.ylabel_style = {'fontsize': 5}\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. BIC plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dist = 50 # correlation distance in km\n",
    "time_steps = ['2018-01','2018-07']  # time steps to be used into account\n",
    "Nrun = 10 # number of runs for each k\n",
    "NK = 20 # max number of classes to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 'PRES_INTERPOLATED'\n",
    "var_name_mdl = ['temp', 'sal']\n",
    "\n",
    "# pcm feature\n",
    "z = ds[z_dim]\n",
    "pcm_features = {var_name_mdl[0]: z, var_name_mdl[1]: z}\n",
    "\n",
    "var_name_ds = ['temp', 'sal']\n",
    "# Variable to be fitted {variable name in model: variable name in dataset}\n",
    "features_in_ds = {var_name_mdl[0] : var_name_ds[0], var_name_mdl[1] : var_name_ds[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_dist_matrix(lats, lons):\n",
    "    '''Calculate distance matrix\n",
    "\n",
    "           Parameters\n",
    "           ----------\n",
    "               lats: latitude vector\n",
    "               lons: longitude vector\n",
    "\n",
    "           Returns\n",
    "           ------\n",
    "               Distance maytrix in int16\n",
    "\n",
    "               '''    \n",
    "    from sklearn.metrics.pairwise import haversine_distances\n",
    "    from math import radians\n",
    "    \n",
    "    lats_in_radians = np.array([radians(_) for _ in lats])\n",
    "    lons_in_radians = np.array([radians(_) for _ in lons])\n",
    "    coords_in_radians = np.column_stack((lats_in_radians, lons_in_radians))\n",
    "    dist_matrix = haversine_distances(coords_in_radians).astype(np.float32)\n",
    "    dist_matrix = dist_matrix * 6371  # multiply by Earth radius to get kilometers\n",
    "    dist_matrix = dist_matrix.astype(np.int16)\n",
    "    \n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regulargrid_dataset(ds, corr_dist, season='all'):\n",
    "    '''Re-sampling od the dataset selecting profiles separated the correlation distance\n",
    "\n",
    "           Parameters\n",
    "           ----------\n",
    "               ds: reference profiles dataset\n",
    "               corr_dist: correlation distance\n",
    "               dist_matrix: distannces matrix\n",
    "               season: choose season: 'DJF', 'MAM', 'JJA','SON' (default: 'all')\n",
    "\n",
    "           Returns\n",
    "           ------\n",
    "               Re-sampled dataset\n",
    "\n",
    "               '''\n",
    "    \n",
    "    ds['n_profiles'] = np.arange(len(ds['n_profiles']))\n",
    "    # create mask\n",
    "    mask_s = np.empty((1,len(ds['n_profiles'].values)))\n",
    "    mask_s[:] = np.NaN\n",
    "    ds[\"mask_s\"]=(['n_profiles'],  np.squeeze(mask_s))\n",
    "    \n",
    "    plus_degrees = corr_dist/111 +1 # from km to degrees\n",
    "    \n",
    "    #loop\n",
    "    n_iterations = range(len(ds['n_profiles'].values))\n",
    "    for i in n_iterations:\n",
    "        \n",
    "        # choose random profile\n",
    "        random_p = np.random.choice(ds['n_profiles'].where(np.isnan(ds['mask_s']), drop=True).values, 1, replace=False)\n",
    "        random_p = int(random_p[0])\n",
    "        lat_p = ds['lat'].sel(n_profiles = random_p).values\n",
    "        long_p = ds['long'].sel(n_profiles = random_p).values\n",
    "        \n",
    "        # dataset arround random point\n",
    "        ds_slice = ds.where(ds['lat'] > (lat_p - plus_degrees), drop=True)\n",
    "        ds_slice = ds_slice.where(ds_slice['lat'] < (lat_p + plus_degrees), drop=True)\n",
    "        ds_slice = ds_slice.where(ds_slice['long'] > (long_p - plus_degrees), drop=True)\n",
    "        ds_slice = ds_slice.where(ds_slice['long'] < (long_p + plus_degrees), drop=True)\n",
    "        random_p_i = np.argwhere(ds_slice['n_profiles'].values == random_p)\n",
    "        \n",
    "        # calculate distance matrix\n",
    "        dist_matrix = cal_dist_matrix(ds_slice['lat'].values, ds_slice['long'].values)\n",
    "        \n",
    "        # points near than corr_dist = 1\n",
    "        mask_dist = np.isnan(ds_slice['mask_s'].values)*1\n",
    "        dist_vector = np.array(np.squeeze(dist_matrix[:,random_p_i])).astype('float')*np.array(mask_dist)\n",
    "        dist_vector[dist_vector == 0] = np.NaN\n",
    "        bool_near_points = (dist_vector < corr_dist)\n",
    "        n_profiles_near_points = ds_slice['n_profiles'].values[bool_near_points]\n",
    "        \n",
    "        # change mask\n",
    "        ds['mask_s'][random_p] = 1\n",
    "        ds['mask_s'][n_profiles_near_points] = 0\n",
    "        \n",
    "        # stop condition\n",
    "        #print(sum(np.isnan(ds['mask_s'].values)))\n",
    "        if np.any(np.isnan(ds['mask_s'])) == False:\n",
    "            print('no more points to delate')\n",
    "            print(i)\n",
    "            break\n",
    "                            \n",
    "    # choose season\n",
    "    if 'all' not in season:\n",
    "        season_idxs = ds.groupby('dates.season').groups\n",
    "\n",
    "        season_select = []\n",
    "        for key in season:\n",
    "            season_select = np.concatenate(\n",
    "                (season_select, np.squeeze(season_idxs.get(key))))\n",
    "\n",
    "        if len(season) == 1:\n",
    "            season_select = np.array(season_select)\n",
    "\n",
    "        season_select = np.sort(season_select.astype(int))\n",
    "        ds = ds.isel(n_profiles=season_select)\n",
    "    \n",
    "    ds_t = ds.where(ds['mask_s']== 1, drop=True)\n",
    "    \n",
    "    del dist_matrix\n",
    "\n",
    "    return ds_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIC_cal(X, k, pcm_features):\n",
    "    ''' Function that calculates BIC for a number of classes k\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "                X: dataset after preprocessing\n",
    "                k: number of classes\n",
    "\n",
    "            Returns\n",
    "            ------\n",
    "                BIC: BIC value\n",
    "                k: number of classes\n",
    "\n",
    "           '''\n",
    "\n",
    "    # create model\n",
    "    m = pcm(K=k + 1, features=pcm_features)\n",
    "    # fit model\n",
    "    m._classifier.fit(X)\n",
    "\n",
    "    # calculate LOG LIKEHOOD\n",
    "    llh = m._classifier.score(X)\n",
    "\n",
    "    # calculate Nb of independant parameters to estimate\n",
    "    # we suppose m._classifier.covariance_type == 'full'\n",
    "    _, n_features = m._classifier.means_.shape\n",
    "    cov_params = m._classifier.n_components * \\\n",
    "                 n_features * (n_features + 1) / 2.\n",
    "    mean_params = n_features * m._classifier.n_components\n",
    "    Nf = int(cov_params + mean_params + m._classifier.n_components - 1)\n",
    "\n",
    "    # calculate bic\n",
    "    N_samples = X.shape[0]\n",
    "    BIC = (-2 * llh * N_samples + Nf * np.log(N_samples))\n",
    "    # BIC = m._classifier.bic(X)\n",
    "\n",
    "    return BIC, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_run = get_regulargrid_dataset(ds, corr_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj=ccrs.PlateCarree()\n",
    "subplot_kw = {'projection': proj}\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(\n",
    "            12, 12), dpi=120, facecolor='w', edgecolor='k', subplot_kw=subplot_kw)\n",
    "\n",
    "p1 = ax.scatter(ds_run['long'], ds_run['lat'], s=3, transform=proj, label='Argo reference data')\n",
    "\n",
    "land_feature = cfeature.NaturalEarthFeature(\n",
    "            category='physical', name='land', scale='50m', facecolor=[0.9375, 0.9375, 0.859375])\n",
    "ax.add_feature(land_feature, edgecolor='black')\n",
    "\n",
    "defaults = {'linewidth': .5, 'color': 'gray', 'alpha': 0.5, 'linestyle': '--'}\n",
    "gl = ax.gridlines(crs=ax.projection,draw_labels=True, **defaults)\n",
    "gl.xlocator = mticker.FixedLocator(np.arange(-180, 180+1, 4))\n",
    "gl.ylocator = mticker.FixedLocator(np.arange(-90, 90+1, 4))\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'fontsize': 5}\n",
    "gl.ylabel_style = {'fontsize': 5}\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# create distance matrix\n",
    "#dist_matrix = cal_dist_matrix(ds['lat'].values, ds['long'].values)\n",
    "\n",
    "BIC = np.zeros((NK-1, Nrun))\n",
    "\n",
    "for run in range(Nrun):\n",
    "    print(run)\n",
    "    # get sub-sampling dataset\n",
    "    print('subsampling ...')\n",
    "    ds_run = get_regulargrid_dataset(ds, corr_dist)\n",
    "    \n",
    "    # pre-processing\n",
    "    # K=4 it is not important, it is only used for preprocess data\n",
    "    print('preprocesing ...')\n",
    "    m = pcm(K=4, features=pcm_features)\n",
    "    X, sampling_dims = m.preprocessing(ds_run, features=features_in_ds, dim=z_dim, action='fit')\n",
    "    \n",
    "    print('bic calculation ...')\n",
    "    BICi=[]\n",
    "    for k in range(1,NK):\n",
    "        print(k)\n",
    "        print(BIC_cal(X, k, pcm_features)[0])\n",
    "        BICi.append(BIC_cal(X, k, pcm_features)[0])\n",
    "        \n",
    "    BIC[:, run] = np.array([i for i in BICi])\n",
    "    print(BIC)\n",
    "    \n",
    "BICmean = np.mean(BIC, axis=1)\n",
    "BICstd = np.std(BIC, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(\n",
    "            6, 6), dpi=120, facecolor='w', edgecolor='k')\n",
    "ax.plot(np.arange(NK-1) + 1, BICmean, label='BIC mean')\n",
    "ax.plot(np.arange(NK-1) + 1, BICmean + BICstd,\n",
    "             color=[0.7] * 3, linewidth=0.5, label='BIC std')\n",
    "ax.plot(np.arange(NK-1) + 1, BICmean - BICstd, color=[0.7] * 3, linewidth=0.5)\n",
    "plt.ylabel('BIC')\n",
    "plt.xlabel('Number of classes')\n",
    "plt.xticks(np.arange(NK) + 1)\n",
    "plt.title('Bayesian information criteria (BIC)')\n",
    "\n",
    "print('BIC min: ' + str(np.argmin(BICmean) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BlueCloud",
   "language": "python",
   "name": "bluecloud"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
